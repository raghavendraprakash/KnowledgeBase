<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_bgqk0dp9um2-5>li:before{content:"-  "}.lst-kix_bgqk0dp9um2-4>li:before{content:"-  "}.lst-kix_bgqk0dp9um2-8>li:before{content:"-  "}.lst-kix_bgqk0dp9um2-1>li:before{content:"-  "}.lst-kix_bgqk0dp9um2-3>li:before{content:"-  "}.lst-kix_bgqk0dp9um2-2>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-6>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-8>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-3>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-7>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-4>li:before{content:"-  "}.lst-kix_bgqk0dp9um2-7>li:before{content:"-  "}.lst-kix_bgqk0dp9um2-6>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-5>li:before{content:"-  "}ul.lst-kix_i7cysmii0je3-0{list-style-type:none}ul.lst-kix_i7cysmii0je3-2{list-style-type:none}ul.lst-kix_i7cysmii0je3-1{list-style-type:none}ul.lst-kix_i7cysmii0je3-4{list-style-type:none}ul.lst-kix_i7cysmii0je3-3{list-style-type:none}ul.lst-kix_i7cysmii0je3-6{list-style-type:none}ul.lst-kix_i7cysmii0je3-5{list-style-type:none}ul.lst-kix_i7cysmii0je3-8{list-style-type:none}ul.lst-kix_i7cysmii0je3-7{list-style-type:none}.lst-kix_bgqk0dp9um2-0>li:before{content:"-  "}.lst-kix_7hjben6ym3g1-1>li:before{content:"-  "}.lst-kix_7hjben6ym3g1-0>li:before{content:"-  "}ul.lst-kix_rk2x8oyk5oln-0{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-4{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-3{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-2{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-1{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-8{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-7{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-6{list-style-type:none}ul.lst-kix_rk2x8oyk5oln-5{list-style-type:none}.lst-kix_rk2x8oyk5oln-0>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-2>li:before{content:"-  "}.lst-kix_rk2x8oyk5oln-1>li:before{content:"-  "}.lst-kix_l76nckrgby7g-8>li:before{content:"\0025a0   "}.lst-kix_l76nckrgby7g-6>li:before{content:"\0025cf   "}.lst-kix_l76nckrgby7g-7>li:before{content:"\0025cb   "}.lst-kix_l76nckrgby7g-4>li:before{content:"\0025cb   "}.lst-kix_l76nckrgby7g-5>li:before{content:"\0025a0   "}ul.lst-kix_bgqk0dp9um2-7{list-style-type:none}ul.lst-kix_7hjben6ym3g1-8{list-style-type:none}.lst-kix_l76nckrgby7g-0>li:before{content:"\0025cf   "}.lst-kix_l76nckrgby7g-1>li:before{content:"\0025cb   "}ul.lst-kix_bgqk0dp9um2-8{list-style-type:none}ul.lst-kix_7hjben6ym3g1-5{list-style-type:none}ul.lst-kix_bgqk0dp9um2-3{list-style-type:none}ul.lst-kix_7hjben6ym3g1-4{list-style-type:none}.lst-kix_l76nckrgby7g-2>li:before{content:"\0025a0   "}.lst-kix_l76nckrgby7g-3>li:before{content:"\0025cf   "}ul.lst-kix_bgqk0dp9um2-4{list-style-type:none}ul.lst-kix_7hjben6ym3g1-7{list-style-type:none}ul.lst-kix_bgqk0dp9um2-5{list-style-type:none}ul.lst-kix_7hjben6ym3g1-6{list-style-type:none}ul.lst-kix_bgqk0dp9um2-6{list-style-type:none}ul.lst-kix_7hjben6ym3g1-1{list-style-type:none}ul.lst-kix_7hjben6ym3g1-0{list-style-type:none}ul.lst-kix_bgqk0dp9um2-0{list-style-type:none}ul.lst-kix_7hjben6ym3g1-3{list-style-type:none}ul.lst-kix_bgqk0dp9um2-1{list-style-type:none}ul.lst-kix_7hjben6ym3g1-2{list-style-type:none}ul.lst-kix_bgqk0dp9um2-2{list-style-type:none}.lst-kix_ptg9smmbks9r-8>li:before{content:"-  "}.lst-kix_h8zodwjgk1e5-4>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-7>li:before{content:"-  "}ul.lst-kix_h8zodwjgk1e5-1{list-style-type:none}ul.lst-kix_h8zodwjgk1e5-0{list-style-type:none}.lst-kix_h8zodwjgk1e5-5>li:before{content:"-  "}ul.lst-kix_h8zodwjgk1e5-5{list-style-type:none}ul.lst-kix_h8zodwjgk1e5-4{list-style-type:none}ul.lst-kix_h8zodwjgk1e5-3{list-style-type:none}.lst-kix_h8zodwjgk1e5-6>li:before{content:"-  "}ul.lst-kix_h8zodwjgk1e5-2{list-style-type:none}.lst-kix_h8zodwjgk1e5-7>li:before{content:"-  "}.lst-kix_7hjben6ym3g1-7>li:before{content:"-  "}.lst-kix_h8zodwjgk1e5-8>li:before{content:"-  "}.lst-kix_7hjben6ym3g1-8>li:before{content:"-  "}.lst-kix_7hjben6ym3g1-5>li:before{content:"-  "}ul.lst-kix_l76nckrgby7g-7{list-style-type:none}.lst-kix_i7cysmii0je3-8>li:before{content:"\0025a0   "}ul.lst-kix_ptg9smmbks9r-2{list-style-type:none}ul.lst-kix_l76nckrgby7g-6{list-style-type:none}ul.lst-kix_ptg9smmbks9r-1{list-style-type:none}ul.lst-kix_ptg9smmbks9r-0{list-style-type:none}ul.lst-kix_l76nckrgby7g-8{list-style-type:none}ul.lst-kix_l76nckrgby7g-3{list-style-type:none}.lst-kix_i7cysmii0je3-6>li:before{content:"\0025cf   "}ul.lst-kix_l76nckrgby7g-2{list-style-type:none}.lst-kix_7hjben6ym3g1-2>li:before{content:"-  "}.lst-kix_7hjben6ym3g1-6>li:before{content:"-  "}ul.lst-kix_l76nckrgby7g-5{list-style-type:none}.lst-kix_i7cysmii0je3-7>li:before{content:"\0025cb   "}ul.lst-kix_l76nckrgby7g-4{list-style-type:none}.lst-kix_i7cysmii0je3-4>li:before{content:"\0025cb   "}ul.lst-kix_h8zodwjgk1e5-8{list-style-type:none}ul.lst-kix_h8zodwjgk1e5-7{list-style-type:none}ul.lst-kix_l76nckrgby7g-1{list-style-type:none}ul.lst-kix_ptg9smmbks9r-8{list-style-type:none}ul.lst-kix_h8zodwjgk1e5-6{list-style-type:none}ul.lst-kix_l76nckrgby7g-0{list-style-type:none}ul.lst-kix_ptg9smmbks9r-7{list-style-type:none}.lst-kix_7hjben6ym3g1-3>li:before{content:"-  "}ul.lst-kix_ptg9smmbks9r-6{list-style-type:none}ul.lst-kix_ptg9smmbks9r-5{list-style-type:none}.lst-kix_7hjben6ym3g1-4>li:before{content:"-  "}.lst-kix_i7cysmii0je3-5>li:before{content:"\0025a0   "}ul.lst-kix_ptg9smmbks9r-4{list-style-type:none}ul.lst-kix_ptg9smmbks9r-3{list-style-type:none}.lst-kix_i7cysmii0je3-0>li:before{content:"\0025cf   "}.lst-kix_i7cysmii0je3-2>li:before{content:"\0025a0   "}.lst-kix_i7cysmii0je3-3>li:before{content:"\0025cf   "}.lst-kix_i7cysmii0je3-1>li:before{content:"\0025cb   "}.lst-kix_h8zodwjgk1e5-3>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-4>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-6>li:before{content:"-  "}.lst-kix_h8zodwjgk1e5-1>li:before{content:"-  "}.lst-kix_h8zodwjgk1e5-2>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-1>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-5>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-2>li:before{content:"-  "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_h8zodwjgk1e5-0>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-3>li:before{content:"-  "}.lst-kix_ptg9smmbks9r-0>li:before{content:"-  "}ol{margin:0;padding:0}table td,table th{padding:0}.c12{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c4{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c8{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c15{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c13{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c7{padding:0;margin:0}.c3{margin-left:36pt;padding-left:0pt}.c6{margin-left:72pt;padding-left:0pt}.c16{color:inherit;text-decoration:inherit}.c2{height:11pt}.c10{margin-left:36pt}.c11{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c13 doc-content"><h1 class="c15" id="h.9xdjkq1rl0os"><span class="c14">All in One at a Glance</span></h1><h2 class="c4" id="h.v8o8f2832439"><span class="c5">License</span></h2><p class="c1"><span class="c0">Langfuse is licensed under MIT license. The core product and all Langfuse maintained integrations and SDK are fully open source and available under MIT license.</span></p><p class="c1"><span class="c0">There are EE features in the code repo under the folders /ee and /web/src/ee. While you can take a look at the code, the self-hosted version will not use these features unless you have a commercial license. These features are available only for SaaS version (cloud version) or EE self-hosted mode.</span></p><h3 class="c8" id="h.as2gz3z7no92"><span class="c12">How do you experiment with Langfuse?</span></h3><p class="c1"><span class="c0">Add &lt;release_tag&gt; to your generation; Filter basis release; Analyze performance</span></p><p class="c1"><span class="c0">[Q] &nbsp;What is the impact of switching to a new model?</span></p><p class="c1"><span class="c0">[Q] Why did latency in this chain increase?</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">What all can you monitor with Langfuse?</span></p><p class="c1"><span class="c0">Model usage and cost</span></p><p class="c1"><span class="c0">Scores and evaluation</span></p><p class="c1"><span class="c0">LLM Security</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.f24szjstvwh0"><span>What metrics can you collect with </span><span>Langfuse</span><span class="c5">?</span></h2><p class="c1"><span class="c0">[Governance] Quality is measured through</span></p><ul class="c7 lst-kix_h8zodwjgk1e5-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">User feedback</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Model based scoring</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Human in the loop score</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Custom scoring</span></li></ul><p class="c1"><span class="c0">[Q] Track how changes to LLM applications affected your metrics?</span></p><p class="c1"><span class="c0">[Q] Differentiate between use cases, features how different prompts affected your metrics?</span></p><p class="c1"><span class="c0">[Q] Add more context such as user context, tenant context, team context and track how various traces are performing with respect expected results</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.ehjn2yo255mv"><span class="c5">Can I export captured observations and analyze separately?</span></h2><p class="c1"><span class="c0">Feasibility of exporting the collected metrics and analyzing it outside Langfuse - It is possible to export either through UI or using API</span></p><p class="c1"><span class="c9"><a class="c16" href="https://www.google.com/url?q=https://api.reference.langfuse.com/%23get-/api/public/observations&amp;sa=D&amp;source=editors&amp;ust=1724847496143751&amp;usg=AOvVaw3KtZGuTbhlIkOKn9MjM9WV">https://api.reference.langfuse.com/#get-/api/public/observations</a></span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.fnct8bw9nz7v"><span class="c5">Prompt management</span></h2><p class="c1"><span class="c0">One of the important phases in LLM engineering. Langfuse is a Prompt content management system.</span></p><ul class="c7 lst-kix_7hjben6ym3g1-0 start"><li class="c1 c3 li-bullet-0"><span>You can </span><span class="c11">deploy </span><span class="c0">new prompts without redeploying your application</span></li><li class="c1 c3 li-bullet-0"><span>With </span><span>Langfuse</span><span class="c0">&nbsp;console, even non-technical users can create prompts</span></li><li class="c1 c3 li-bullet-0"><span class="c0">You can rollback to a previous version of a prompt with ease</span></li></ul><p class="c1"><span class="c0">With tracing, you can track and analyze the performance of prompt versions.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.3b31m3tlz8h7"><span class="c5">LLM Traceability</span></h2><p class="c1"><span class="c0">LLM Applications use complex abstractions like chains, agents, and advance prompts.</span></p><p class="c1"><span class="c0">The nested traces in Langfuse help to analyze the root causes of the problems.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">How can Langfuse help with tracing?</span></p><p class="c1"><span class="c0">With Langfuse, you can capture the full context of the execution</span></p><ul class="c7 lst-kix_ptg9smmbks9r-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">Context</span></li><li class="c1 c3 li-bullet-0"><span class="c0">API Calls</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Prompts</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Parallelism</span></li><li class="c1 c3 li-bullet-0"><span class="c0">More</span></li></ul><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.672tch88t31b"><span class="c5">Can I track model usage and cost?</span></h2><p class="c1"><span class="c0">Yes.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.b185tgg8i6xu"><span class="c5">Can I collect user feedback?</span></h2><p class="c1"><span class="c0">Yes. Useful for governance.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.byn99g807fkq"><span class="c5">[Q] How can I identify low-quality outputs with Langfuse?</span></h2><p class="c1"><span class="c0">With captured traces and responses, either you can employ humans in the loop or AI powered analysis to determine the quality of the output. You can tag low quality outputs and create a dataset that is distinguishable from high quality output.</span></p><h2 class="c4" id="h.aiejzfpgaqs0"><span class="c5">[Q] How can I use Langfuse to improve AI applications?</span></h2><p class="c1"><span class="c0">With captured traces, responses, it is possible to conduct in-depth analysis of the data (input and output). If you want to fine tune your LLM with these data, you can fine tune.</span></p><p class="c1"><span class="c0">If you plan to create your own dedicated SLM or LLM, you can use this data to pre-train your model for accuracy.</span></p><p class="c1"><span class="c0">Since, the analysis takes care of governance aspects, the data you would be using would be safe in terms of governance.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span>What is the </span><span>Langfuse</span><span class="c0">&nbsp;trace?</span></p><p class="c1"><span class="c0">A Trace typically represents a single request or operation.</span></p><p class="c1"><span class="c0">Contains input and output of the function, including metadata of the request, such as user, session, and tags.</span></p><p class="c1"><span class="c0">Each trace can contain multiple observations to log individual steps of the execution. There are different types of observation.</span></p><ul class="c7 lst-kix_l76nckrgby7g-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">Events [Discrete events]</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Spans [Duration of units of work]</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Generations [Spans used to log AI model&rsquo;s generation]</span></li></ul><p class="c1 c10"><span class="c0">The generation may contain model attributes, prompt used, completion. For generation, token usage and costs are automatically calculated.</span></p><p class="c1"><span class="c0">Note that observations can be nested.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 843.00px; height: 552.00px;"><img alt="" src="images/image2.png" style="width: 843.00px; height: 552.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.vr25odoklzjg"><span class="c5">Some basic concepts</span></h2><h2 class="c4" id="h.rakn15jz2a35"><span class="c5">What is a session?</span></h2><p class="c1"><span class="c0">Session represents the entire interaction with the LLM application. Session groups the traces together.</span></p><p class="c1"><span class="c0">Example:</span></p><p class="c1"><span class="c0">User is interacting with your LLM application in a chat model. Then all the traces of this interaction are grouped under this session.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 550.00px; height: 653.00px;"><img alt="" src="images/image1.png" style="width: 550.00px; height: 653.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.5lcrvdjys8vv"><span class="c5">What is a User?</span></h2><p class="c1"><span class="c0">User is identified by a unique identifier such as userId. It can be an email, username or any other unique identifier. It is optional, but having one helps you get more information. Going by the previous example, one user may initiate many chat sessions.</span></p><p class="c1"><span class="c0">Hierarchy: User contains Sessions; Session contains Traces; Trace contains Generation/s.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.k6pa57i8a36j"><span class="c5">What is Metadata?</span></h2><p class="c1"><span class="c0">With metadata, you can enrich the observable entities such as users, sessions, traces, generations, applications, and experiments.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.kkyu57oxgugp"><span class="c5">What about tagging traces?</span></h2><p class="c1"><span class="c0">You can categorize and filter traces using tags. You can either add tags to traces through Langfuse SDK or through UI. Note that you can add multiple tags to a single trace.</span></p><p class="c1"><span class="c0">Each trace has a unique URL that can be shared. This would be useful when your customers want to observe specific requests first hand.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.7zxdrzs4ms5o"><span class="c5">Dive deep - Governance aids [TBD]</span></h2><p class="c1"><span class="c0">Scores and Evaluation</span></p><p class="c1"><span class="c0">LLM Security</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.fws2gt26pi5t"><span class="c5">List the LLM Evaluation metrics</span></h2><p class="c1"><span class="c0">Perplexity [How well an LLM predicts a given sequence of words; Lower the better]</span></p><p class="c1"><span class="c0">Accuracy [Correctness (correct predictions/total predictions)]</span></p><p class="c1"><span class="c0">Coherence and Consistency [Evaluated through human intervention or through automation - how logical and consistent the response is]</span></p><p class="c1"><span class="c0">Factual accuracy [Factual correctness, how? Tbd]</span></p><p class="c1"><span class="c0">Bias and Fairness metrics [Presence of biases, unfair representations in outputs]</span></p><p class="c1"><span class="c0">Human evaluation [Assessment of overall quality, naturalness, and appropriateness of model output]</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Model provider can provide the following -</span></p><p class="c1"><span class="c0">BPC/BPW (Bits per Character or Bits per Word) - Measure of compression</span></p><p class="c1"><span class="c0">F1 Score - Measure of model&rsquo;s accuracy. Commonly used in NLP tasks such as NER recognition and text classification. It is the harmonic mean of precision and recall.</span></p><p class="c1"><span class="c0">BLEU (Bilingual Evaluation Understudy) - Quality of ML generated text by comparing to human written reference texts (commonly used in machine translation.</span></p><p class="c1"><span class="c0">ROUGE (Recall Oriented Understudy for Gisting Evaluation) - Quality of summaries generated by LLM by comparing them to human written reference summaries</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.me9frabtmb7z"><span class="c5">What is an evaluation?</span></h2><p class="c1"><span class="c0">Evaluation is a critical aspect of developing and deploying LLM applications. Depending on the use case and the stage of the development process, teams use different methods of evaluation.</span></p><p class="c1"><span class="c0">Langfuse provides a flexible scoring system to capture these evaluations and make them actionable.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.bljuzqf74sjk"><span class="c5">What are the different evaluation methods?</span></h2><p class="c1"><span class="c0">Each method varies in frequency, cost, and quality.</span></p><p class="c1"><span class="c0">Manual annotation: Manually annotate data in the UI</span></p><p class="c1"><span class="c0">User feedback: Explicitly collect feedback. Eg. 1-5 star rating Or Implicit derivation - Click through rate, accepting/rejecting model generated outputs, human in the loop, time spent on a page</span></p><p class="c1"><span class="c0">Model based evaluation: Langfuse managed evals or external libraries such as OpenAI Evals, Whylabs Langkit, Langchain Evaluators, RAGAS for RAG pipelines, custom model outputs.</span></p><p class="c1"><span class="c0">Custom: Run time quality checks, custom link to annotation tools, external evaluation pipelines that sync with Langfuse.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.oo33a8xirl1r"><span class="c5">What is a score?</span></h2><p class="c1"><span class="c0">Stores evaluation metrics. </span></p><p class="c1"><span class="c0">Always related to a trace and [optionally] can be attached to specific observations within a trace.</span></p><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.y0gjpiyxjuc9"><span class="c5">How can you score in Langfuse?</span></h2><ul class="c7 lst-kix_i7cysmii0je3-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">Segment all traces by scores</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Find a trace with low quality score</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Report details so that you can drill down to specific use cases and user segment</span></li></ul><p class="c1 c2"><span class="c0"></span></p><h2 class="c4" id="h.83u82p9g3fe1"><span class="c5">What can you determine with what kind of scores?</span></h2><p class="c1"><span class="c0">You can determine quality of output with Factual accuracy, Completeness of the information provided, Verification against hallucinations.</span></p><p class="c1"><span class="c0">You can determine the style of response with Sentiment, Tonality of the content, Potential toxicity</span></p><p class="c1"><span class="c0">You can determine security through Similarity to prevalent prompt injections, instances of model refusals.</span></p><p class="c1"><span class="c0">The scoring system allows the evaluation of various elements of performance of the LLM application.</span></p><h2 class="c4" id="h.kdt4k181uwi3"><span class="c5">What are the possible threats for LLM security?</span></h2><p class="c1"><span class="c0">Prompt injection, PII leakage, Harmful prompts. You can use Langfuse to monitor and protect against these risks and investigate further when they occur.</span></p><h2 class="c4" id="h.59mxig3asu9n"><span class="c5">How does LLM security work?</span></h2><p class="c1"><span class="c0">We can address LLM security with a combination of runtime security measures through LLM security libraries and evaluating the effectiveness of these measures with Langfuse.</span></p><h2 class="c4" id="h.8l5neycmvuaf"><span class="c5">How do you ensure run-time security measures?</span></h2><p class="c1"><span class="c0">There are popular libraries that can be used to mitigate LLM security risks.</span></p><ul class="c7 lst-kix_rk2x8oyk5oln-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">LLM Guard</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Prompt Armor</span></li><li class="c1 c3 li-bullet-0"><span class="c0">NeMo Guardrails</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Microsoft Azure AI Content Safety</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Lakera</span></li></ul><p class="c1"><span class="c0">You can use these libraries to catch and block potentially harmful or inappropriate prompt before sending to the model</span></p><p class="c1"><span class="c0">You can redact sensitive PII/PHI before sending into th model, then un-redact from the response</span></p><p class="c1"><span class="c0">You can evaluate prompts and completions on toxicity, relevance, sensitive material at runtime and block the response if necessary.</span></p><h2 class="c4" id="h.4c5akhxknf8y"><span>How do you monitor and evaluate security measures with </span><span>Langfuse</span><span class="c5">?</span></h2><p class="c1"><span class="c0">You can use Langfuse tracing and gain visibility and confidence in each step of the security mechanism.</span></p><ul class="c7 lst-kix_bgqk0dp9um2-0 start"><li class="c1 c3 li-bullet-0"><span class="c0">Manually inspect traces to investigate security issues</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Monitor security scores over time in Langfuse dashboard</span></li><li class="c1 c3 li-bullet-0"><span class="c0">Evaluate the effectiveness of security tools, validate security checks. Teams can identify which security risks are most prevalent and build more robust tools around specific issues.</span></li></ul><ul class="c7 lst-kix_bgqk0dp9um2-1 start"><li class="c1 c6 li-bullet-0"><span class="c0">Annotate in UI (Annotate, Share traces, compare the security scores)</span></li><li class="c1 c6 li-bullet-0"><span class="c0">Automated evaluation (Model based evaluations will run async and can scan traces for things such as toxicity, sensitivity to flag potential risks, identify gaps in LLM security setup)</span></li></ul><ul class="c7 lst-kix_bgqk0dp9um2-0"><li class="c1 c3 li-bullet-0"><span class="c0">Track latency - Some LLM security checks need to be awaited before the model can be called, others block response to the user. Langfuse helps dissect the latencies of these checks with a trace to understand whether the checks are worth the wait.</span></li></ul><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p></body></html>